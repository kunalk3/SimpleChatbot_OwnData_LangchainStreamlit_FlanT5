{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Importing Libraries\n",
    "\n",
    "<b>- TextLoader, UnstructuredPDFLoader, PyPDFLoader:</b> These are used to load different types of documents, including plain text files, PDFs, and URLs, into the LangChain pipeline. In this case, PyPDFLoader is specifically used to load PDF documents.\n",
    "\n",
    "<b>- CharacterTextSplitter, RecursiveCharacterTextSplitter:</b> These are used to split the loaded documents into smaller chunks. For example, RecursiveCharacterTextSplitter splits the text recursively based on a specified chunk size, overlap, and separator (e.g., paragraphs, sentences).\n",
    "\n",
    "<b>- HuggingFaceEmbeddings:</b> This is used to create embeddings for the documents using a HuggingFace model (like T5, BERT, etc.).\n",
    "\n",
    "<b>- FAISS:</b> FAISS (Facebook AI Similarity Search) is used as a vector store for efficient similarity search. It allows for the fast retrieval of similar documents given an embedding.\n",
    "\n",
    "<b>- load_qa_chain:</b> This is used for setting up a question-answering chain that uses a language model to answer queries based on documents.\n",
    "\n",
    "<b>- HuggingFaceHub:</b> This is used to interact with HuggingFace models, providing access to pre-trained models like flan-t5-xxl (which is a large language model).\n",
    "\n",
    "<b>- VectorstoreIndexCreator:</b> This is used for creating a vector store and indexing documents using tools like ChromaDB, though it's not directly used in this code.\n",
    "\n",
    "<b>- RetrievalQA:</b> This chain is used to integrate document retrieval and question answering. It uses a retriever (like FAISS) to get relevant documents and a language model to answer questions based on those documents.\n",
    "\n",
    "<b>- os / dotenv:</b> These are used for loading environment variables from a .env file, which is typically used for storing sensitive information like API tokens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader, UnstructuredPDFLoader, UnstructuredURLLoader, PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS  \n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.chains import RetrievalQA\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Loading and Splitting the PDF:\n",
    "\n",
    "In general, LLM retrieves contextual documents from an external dataset as part of its execution. This is useful when we want to ask questions about specific documents (e.g., PDFs, videos, etc). If we want to create an application to chat with our data, we need to first load our data into a format where it can be worked with.\n",
    "\n",
    "<p align=\"center\"><img src=\"./assets_img/a1.PNG\" width=\"60%\"/></p>\n",
    "\n",
    "Here, we have PDF document, we use `PyPDFLoader()` to load PDF document. \n",
    "\n",
    "- __Youtube DataLoader:__</b>__ LangChain provides YoutubeAudioLoader that loads videos from YouTube.\n",
    "- __WebBaseLoader:__ WebBaseLoader is used to load URLs from the Internet.\n",
    "- __NotionDirectoryLoader:__ NotionDirectoryLoader is used to load data from Notion.\n",
    "\n",
    "<p align=\"center\"><img src=\"./assets_img/a2.PNG\" width=\"40%\"/></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document pages : 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'GPL Ghostscript 10.01.1', 'creator': 'PyPDF', 'creationdate': '2024-03-07T17:18:45+01:00', 'moddate': '2024-03-07T17:18:45+01:00', 'source': './GenAI_data.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='Austin ¥ Boston ¥ Chicago ¥ Denver ¥ Harrisburg ¥ O lympia ¥ Sacramento ¥ Silicon Valley ¥ Washington, D.C.  \\n \\nARTIFICIAL INTELLIGENCE (AI) & GENERATIVE AI \\n \\nWhat is Artificial Intelligence? \\n \\nArtificial Intelligence (AI) is a field of science concerned with building machines that can reason, \\nlearn, and act in such a way that would normally re quire human intelligence or that involves data \\nwhose scale exceeds what humans can analyze.1 \\n \\nWhat is Generative Artificial Intelligence? \\n \\nAI has been around for decades, but the field has recently garnered significant attention due to \\nadvancements in the subfield of generative AI, and the subsequent release of generative AI chatbots \\nÐ like ChatGPT and Bard Ð for public use. \\n \\nUntil recently, AI was largely used for categorization and pattern recognition to understand and \\nrecommend information.  Now, recent advancements in the field of AI enable us to use AI as a tool \\nto create novel content.2 \\n \\nGenerative Artificial Intelligence (Gen AI), a subset of the field of artificial intelligence, uses AI \\nto create new content, including text, images, musi c, audio, video, and even computer code. 3  \\nGenerative AI builds on existing foundation models, which are models trained on massive generalized \\ndatasets that provide a starting point to develop s pecialized applications more quickly and cost-\\neffectively.4 \\n \\nAI in Our Daily Lives \\nAlthough we are interacting with it in new ways, AI has been a part \\nof our technological landscape for many years Ð oft en working \\nbehind the scenes to enhance the tools we use in our daily lives. \\n \\n§ Predictive Text Ð Predictive text helps users type faster and \\nmore efficiently by suggesting words and correcting spelling \\nmistakes.  For example, as you start typing \"I want to go to \\nthe,\" the keyboard might predict \"store\" or \"park.\"  \\nPredictive text is a standard feature on smartphones and \\ntablets, in email, word processing, and search engines.  \\n \\n§ Navigation Apps Ð GPS navigation uses AI to calculate the \\nfastest route, provide real-time traffic updates, and even \\nsuggest nearby places of interest. \\n \\n§ Filtering & Categorizing Ð AI can help filter content such as \\nspam and categorize data like expenses and images to allow \\nusers to find what they need quickly.  \\n \\nFigure 1: Apple iPhone Predictive Text'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 10.01.1', 'creator': 'PyPDF', 'creationdate': '2024-03-07T17:18:45+01:00', 'moddate': '2024-03-07T17:18:45+01:00', 'source': './GenAI_data.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2'}, page_content='§ Language Translation Ð AI-powered translation services \\ncan translate text and even spoken language in real \\ntime.  \\n \\n§ Virtual Assistants Ð Virtual assistants use AI to \\nunderstand and respond to voice commands or text \\nprompts.  They can set reminders, answer questions, \\ncontrol smart home devices, and more. \\n \\n§ Improved Cybersecurity Ð AI is empowering improved \\ncybersecurity services, helping analysts spot an attack \\nfaster, then better assess its scale and potential impact. \\n \\n \\nThe History of AI \\nAIÕs origins go back decades, and are often traced back to British \\nmathematician and World War II code breaker Alan Turing.5 \\n \\nA TIMELINE: BRIEF HISTORY OF AI \\n \\n§ 1950 Ð Alan Turing published a paper entitled ÒComputing Machinery and Intelligence.Ó6 \\n§ 1956 Ð John McCarthy is credited for coining the phrase Òartificial intelligenceÓ and solidifying \\nthe orientation of the field.7 \\n§ 1966 Ð Joseph Weizenbaum of MIT designed a computer  program, ELIZA, one of the first \\nchatbots, as a tool for emotional connection.8 \\n§ 1997 Ð IBM computer Deep Blue beat the world chess champion. \\n§ 2011 Ð Apple announces Siri Ð the intelligent assistant. \\n IBMÕs Watson beats human contestants on Jeopardy! \\n§ 2017 Ð Google Research publishes Ò Attention is All You Need Ó Ð paving the way for the \\nemergence of generative AI.9 \\n  Google announces AI division Ð Google AI. \\n§ 2022 Ð OpenAI releases ChatGPT. \\n§ 2023 Ð Google releases Bard. \\n  Meta releases LLaMA. \\n \\nGenerative AI is simply the newest major development in the field of artificial intelligence that has \\nbeen powering our lives for years. \\n \\n1 ÒWhat Is Artificial Intelligence (AI)?,Ó Google Cloud, accessed September 19, 2023, https://cloud.google.com/learn/what-is-artificial-intelligence. \\n2 ÒWhat Is Generative AI and What Are Its Applications?,Ó Google Cloud, accessed September 19, 2023, https://cloud.google.com/use-cases/generative-ai. \\n3 ÒWhat Is Generative AI and What Are Its Applications?Ó \\n4 ÒWhat are Foundation Models?Ó AWS, accessed January 15, 2024, https://aws.amazon.com/what-is/foundation-models/. \\n5 ÒOverlooked No More: Alan Turing, Condemned Code Breaker and Computer Visionary,Ó The New York Times, June 5, 2019, sec. Obituaries, \\nhttps://www.nytimes.com/2019/06/05/obituaries/alan-turing-overlooked.html. \\n6 SITNFlash, ÒThe History of Artificial Intelligence,Ó Science in the News (blog), August 28, 2017, https://sitn.hms.harvard.edu/flash/2017/history-artificial-\\nintelligence/. \\n7 James Moor, ÒThe Dartmouth College Artificial Intelligence Conference: The Next Fifty Years,Ó AI Magazine 27, no. 4 (December 15, 2006): 87Ð87, \\nhttps://doi.org/10.1609/aimag.v27i4.1911. \\n8 ÒELIZA Wins Peabody Award | MIT CSAIL,Ó accessed September 20, 2023, https://www.csail.mit.edu/news/eliza-wins-peabody-award. \\n9 Ashish Vaswani et al., ÒAttention Is All You Need,Ó 2017, https://arxiv.org/pdf/1706.03762.pdf. \\nFigure 2: Google Translate')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv() # It loads env variable from .env file.\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\") # Retrieves the HuggingFace API token.\n",
    "loader = PyPDFLoader(\"./GenAI_data.pdf\") # It is used to load the PDF file.\n",
    "pages = loader.load_and_split() # Split the PDF into Pages\n",
    "print('Document pages :', len(pages))\n",
    "pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C) Text Splitting\n",
    "\n",
    "<b>Document splitting:</b> Document Splitting is required to split documents into smaller chunks as we need to maintain meaningful relationships between the chunks.\n",
    "\n",
    "<p align=\"center\"><img src=\"./assets_img/a3.PNG\" width=\"40%\"/></p>\n",
    "\n",
    "- The input text is split based on a defined chunk size with some defined chunk overlap. Chunk Size is a length function to measure the size of the chunk. This is often characters or tokens.\n",
    "- A chunk overlap is used to have little overlap between two chunks and this allows for to have some notion of consistency between 2 chunks\n",
    "\n",
    "<p align=\"center\"><img src=\"./assets_img/a4.PNG\" width=\"50%\"/></p>\n",
    "\n",
    "__Examples:__\n",
    "- Recursive text Splitter\n",
    "\n",
    "        text1 = 'abcdefghijklmnopqrstuvwxyz'\n",
    "        r_splitter.split_text(text1)\n",
    "        # Output - ['abcdefghijklmnopqrstuvwxyz']\n",
    "- Character Text Splitter\n",
    "\n",
    "        text2 = 'abcdefghijklmnopqrstuvwxyzabcdefg'\n",
    "        r_splitter.split_text(text2)\n",
    "        # Output - ['abcdefghijklmnopqrstuvwxyz', 'wxyzabcdefg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'GPL Ghostscript 10.01.1', 'creator': 'PyPDF', 'creationdate': '2024-03-07T17:18:45+01:00', 'moddate': '2024-03-07T17:18:45+01:00', 'source': './GenAI_data.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='Austin ¥ Boston ¥ Chicago ¥ Denver ¥ Harrisburg ¥ O lympia ¥ Sacramento ¥ Silicon Valley ¥ Washington, D.C.  \\n \\nARTIFICIAL INTELLIGENCE (AI) & GENERATIVE AI \\n \\nWhat is Artificial Intelligence? \\n \\nArtificial Intelligence (AI) is a field of science concerned with building machines that can reason, \\nlearn, and act in such a way that would normally re quire human intelligence or that involves data \\nwhose scale exceeds what humans can analyze.1 \\n \\nWhat is Generative Artificial Intelligence? \\n \\nAI has been around for decades, but the field has recently garnered significant attention due to \\nadvancements in the subfield of generative AI, and the subsequent release of generative AI chatbots \\nÐ like ChatGPT and Bard Ð for public use. \\n \\nUntil recently, AI was largely used for categorization and pattern recognition to understand and \\nrecommend information.  Now, recent advancements in the field of AI enable us to use AI as a tool \\nto create novel content.2 \\n \\nGenerative Artificial Intelligence (Gen AI), a subset of the'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 10.01.1', 'creator': 'PyPDF', 'creationdate': '2024-03-07T17:18:45+01:00', 'moddate': '2024-03-07T17:18:45+01:00', 'source': './GenAI_data.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='Generative Artificial Intelligence (Gen AI), a subset of the field of artificial intelligence, uses AI \\nto create new content, including text, images, musi c, audio, video, and even computer code. 3  \\nGenerative AI builds on existing foundation models, which are models trained on massive generalized \\ndatasets that provide a starting point to develop s pecialized applications more quickly and cost-\\neffectively.4 \\n \\nAI in Our Daily Lives \\nAlthough we are interacting with it in new ways, AI has been a part \\nof our technological landscape for many years Ð oft en working \\nbehind the scenes to enhance the tools we use in our daily lives. \\n \\n§ Predictive Text Ð Predictive text helps users type faster and \\nmore efficiently by suggesting words and correcting spelling \\nmistakes.  For example, as you start typing \"I want to go to \\nthe,\" the keyboard might predict \"store\" or \"park.\"  \\nPredictive text is a standard feature on smartphones and \\ntablets, in email, word processing, and search engines.  \\n \\n§ Navigation'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 10.01.1', 'creator': 'PyPDF', 'creationdate': '2024-03-07T17:18:45+01:00', 'moddate': '2024-03-07T17:18:45+01:00', 'source': './GenAI_data.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='in email, word processing, and search engines.  \\n \\n§ Navigation Apps Ð GPS navigation uses AI to calculate the \\nfastest route, provide real-time traffic updates, and even \\nsuggest nearby places of interest. \\n \\n§ Filtering & Categorizing Ð AI can help filter content such as \\nspam and categorize data like expenses and images to allow \\nusers to find what they need quickly.  \\n \\nFigure 1: Apple iPhone Predictive Text'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 10.01.1', 'creator': 'PyPDF', 'creationdate': '2024-03-07T17:18:45+01:00', 'moddate': '2024-03-07T17:18:45+01:00', 'source': './GenAI_data.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2'}, page_content='§ Language Translation Ð AI-powered translation services \\ncan translate text and even spoken language in real \\ntime.  \\n \\n§ Virtual Assistants Ð Virtual assistants use AI to \\nunderstand and respond to voice commands or text \\nprompts.  They can set reminders, answer questions, \\ncontrol smart home devices, and more. \\n \\n§ Improved Cybersecurity Ð AI is empowering improved \\ncybersecurity services, helping analysts spot an attack \\nfaster, then better assess its scale and potential impact. \\n \\n \\nThe History of AI \\nAIÕs origins go back decades, and are often traced back to British \\nmathematician and World War II code breaker Alan Turing.5 \\n \\nA TIMELINE: BRIEF HISTORY OF AI \\n \\n§ 1950 Ð Alan Turing published a paper entitled ÒComputing Machinery and Intelligence.Ó6 \\n§ 1956 Ð John McCarthy is credited for coining the phrase Òartificial intelligenceÓ and solidifying \\nthe orientation of the field.7 \\n§ 1966 Ð Joseph Weizenbaum of MIT designed a computer  program, ELIZA, one of the first \\nchatbots, as a tool for emotional'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 10.01.1', 'creator': 'PyPDF', 'creationdate': '2024-03-07T17:18:45+01:00', 'moddate': '2024-03-07T17:18:45+01:00', 'source': './GenAI_data.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2'}, page_content='ELIZA, one of the first \\nchatbots, as a tool for emotional connection.8 \\n§ 1997 Ð IBM computer Deep Blue beat the world chess champion. \\n§ 2011 Ð Apple announces Siri Ð the intelligent assistant. \\n IBMÕs Watson beats human contestants on Jeopardy! \\n§ 2017 Ð Google Research publishes Ò Attention is All You Need Ó Ð paving the way for the \\nemergence of generative AI.9 \\n  Google announces AI division Ð Google AI. \\n§ 2022 Ð OpenAI releases ChatGPT. \\n§ 2023 Ð Google releases Bard. \\n  Meta releases LLaMA. \\n \\nGenerative AI is simply the newest major development in the field of artificial intelligence that has \\nbeen powering our lives for years. \\n \\n1 ÒWhat Is Artificial Intelligence (AI)?,Ó Google Cloud, accessed September 19, 2023, https://cloud.google.com/learn/what-is-artificial-intelligence. \\n2 ÒWhat Is Generative AI and What Are Its Applications?,Ó Google Cloud, accessed September 19, 2023, https://cloud.google.com/use-cases/generative-ai. \\n3 ÒWhat Is Generative AI and What Are Its Applications?Ó \\n4 ÒWhat are'),\n",
       " Document(metadata={'producer': 'GPL Ghostscript 10.01.1', 'creator': 'PyPDF', 'creationdate': '2024-03-07T17:18:45+01:00', 'moddate': '2024-03-07T17:18:45+01:00', 'source': './GenAI_data.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2'}, page_content='Is Generative AI and What Are Its Applications?Ó \\n4 ÒWhat are Foundation Models?Ó AWS, accessed January 15, 2024, https://aws.amazon.com/what-is/foundation-models/. \\n5 ÒOverlooked No More: Alan Turing, Condemned Code Breaker and Computer Visionary,Ó The New York Times, June 5, 2019, sec. Obituaries, \\nhttps://www.nytimes.com/2019/06/05/obituaries/alan-turing-overlooked.html. \\n6 SITNFlash, ÒThe History of Artificial Intelligence,Ó Science in the News (blog), August 28, 2017, https://sitn.hms.harvard.edu/flash/2017/history-artificial-\\nintelligence/. \\n7 James Moor, ÒThe Dartmouth College Artificial Intelligence Conference: The Next Fifty Years,Ó AI Magazine 27, no. 4 (December 15, 2006): 87Ð87, \\nhttps://doi.org/10.1609/aimag.v27i4.1911. \\n8 ÒELIZA Wins Peabody Award | MIT CSAIL,Ó accessed September 20, 2023, https://www.csail.mit.edu/news/eliza-wins-peabody-award. \\n9 Ashish Vaswani et al., ÒAttention Is All You Need,Ó 2017, https://arxiv.org/pdf/1706.03762.pdf. \\nFigure 2: Google Translate')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RecursiveCharacterTextSplitter: It splits the text into chunks of size 1024 characters, \n",
    "# with an overlap of 64 characters between consecutive chunks which helps in maintaining context while splitting text.\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1024,\n",
    "    chunk_overlap=64,\n",
    "    separators=[r'\\n\\n', r'\\n', r'(?=>\\. )', ' ', '']\n",
    ")\n",
    "\n",
    "# Splitting should happen at double newlines (\\n\\n), single newlines (\\n), after periods, spaces, etc.\n",
    "docs = text_splitter.split_documents(pages) # It splits the pages into smaller chunks.\n",
    "\n",
    "print(len(docs))\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D) Embeddings and Vector Database Creation\n",
    "\n",
    "<p align=\"center\"><img src=\"./assets_img/a5.PNG\" width=\"50%\"/></p>\n",
    "\n",
    "We split up our document into small chunks and now we need to put these chunks into an index so that we are able to retrieve them easily when we want to answer questions on this document. We use embeddings and vector stores for this purpose.\n",
    "\n",
    "- __Vector stores__ and __embeddings__ come after text splitting as we need to store our documents in an easily accessible format. Embeddings take a piece of text and create a numerical representation of the text. \n",
    "- Text with semantically similar content will have similar vectors in embedding space. Thus, we can compare embeddings(vectors) and find texts that are similar.\n",
    "\n",
    "<p align=\"center\"><img src=\"./assets_img/a6.PNG\" width=\"40%\"/> &nbsp <img src=\"./assets_img/a7.PNG\" width=\"40%\"/></p>\n",
    "\n",
    "- A vector store is a database where you can easily look up similar vectors later on. This becomes useful when we try to find documents that are relevant to a question.\n",
    "- When we want to get an answer for a question, we create embeddings of the question and then we compare the embeddings of the question with all the different vectors in the vector store and pick the n most similar.\n",
    "\n",
    "\n",
    "<b>- HuggingFaceEmbeddings:</b> This model generates embeddings for the document chunks using a HuggingFace model. Embeddings are numerical representations of text that capture semantic meaning.\n",
    "\n",
    "<b>- FAISS.from_documents():</b> This takes the document chunks (docs) and their embeddings and stores them in a FAISS vector store. FAISS allows efficient similarity search, which is crucial for retrieving relevant documents when querying.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 384, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ") model_name='sentence-transformers/all-mpnet-base-v2' cache_folder=None model_kwargs={} encode_kwargs={} multi_process=False show_progress=False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x2a400113650>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings()\n",
    "print(embeddings)\n",
    "db = FAISS.from_documents(docs, embeddings)\n",
    "db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E) Model Setup\n",
    "\n",
    "We loads the `large FLAN-T5` model (google/flan-t5-xxl) from HuggingFace's model hub. The model is used for text generation tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceHub(client=<InferenceClient(model='google/flan-t5-xxl', timeout=None)>, repo_id='google/flan-t5-xxl', task='text-generation', model_kwargs={'temperature': 1, 'max_length': 300})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"google/flan-t5-xxl\", # Model: large FLAN-T5 model.\n",
    "    model_kwargs=\n",
    "        {\n",
    "            \"temperature\":1, # Controls output randomness (higher values, more randomness).\n",
    "            \"max_length\":300 # Model can generate max long text if required.\n",
    "        }, \n",
    "        task=\"text-generation\" # Task: text generation tasks.\n",
    "    )\n",
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F) Question-Answering Chain\n",
    "\n",
    "\n",
    "__Similarity Search:__ We will now ask questions using the similarity search method and pass k, which specifies the number of documents that we want to return. Retrieval is important at query time when a query comes in and we want to retrieve the most relevant splits\n",
    "\n",
    "<p align=\"center\"><img src=\"./assets_img/a8.PNG\" width=\"40%\"/> &nbsp <img src=\"./assets_img/a9.PNG\" width=\"40%\"/> </p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RetrievalQA(verbose=False, combine_documents_chain=StuffDocumentsChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\n{context}\\n\\nQuestion: {question}\\nHelpful Answer:\"), llm=HuggingFaceHub(client=<InferenceClient(model='google/flan-t5-xxl', timeout=None)>, repo_id='google/flan-t5-xxl', task='text-generation', model_kwargs={'temperature': 1, 'max_length': 300}), output_parser=StrOutputParser(), llm_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_variable_name='context'), retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002A400113650>, search_kwargs={'k': 3}))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa = RetrievalQA.from_chain_type( # RetrievalQA: It sets up a question-answering chain.\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",  # Method used to create QA chain. 'stuff' meaning the model use all documents for the response.\n",
    "    retriever=db.as_retriever(search_kwargs={ # db.as_retriever: Takes FAISS vector store and retrieves top most relevant documents.\n",
    "        \"k\": 3})  # Top 'k=3' documents will retrieve\n",
    ") \n",
    "qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_QA_chain(q):\n",
    "    chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "    docs = db.similarity_search(q, k=3)\n",
    "    response = chain.run(input_documents=docs, question=q)\n",
    "    start_index = response.find(\"Helpful Answer:\") \n",
    "    if start_index != -1:\n",
    "        answer = response[start_index + len(\"Helpful Answer:\"):].strip()\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's a brief history of AI:\n",
      "\n",
      "- **1950**: Alan Turing published a paper entitled \"Computing Machinery and Intelligence,\" which introduced the concept of a \"learning machine.\"\n",
      "- **1956**: John McCarthy coined the term \"artificial intelligence\" at the Dartmouth Conference, marking the official birth of AI as a field of study.\n",
      "- **1966**: Joseph Weizenbaum created ELIZA, one of the first chatbots, at MIT. ELIZA was designed to simulate a psychotherapist's conversation with a patient.\n",
      "- **1970s-1980s**: AI research focused on expert systems, which used AI to mimic the decision-making abilities of human experts.\n",
      "- **1990s**: The internet boom led to advancements in machine learning, with AI being used for tasks like image and speech recognition.\n",
      "- **2010s**: Deep learning, a subset of machine learning, gained prominence. This led to significant improvements in AI's ability to understand and generate human-like text, images, and speech.\n",
      "- **2020s**: The release of generative AI chatbots like ChatGPT and Bard has brought AI into the mainstream, allowing it to create novel content and engage in complex conversations.\n"
     ]
    }
   ],
   "source": [
    "query = \"Can you give me brief history of AI?\"\n",
    "resp = answer_QA_chain(query)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "# query = \"Can you give me brief history of AI?\"\n",
    "# docs = db.similarity_search(query, k=3)\n",
    "# response = chain.run(input_documents=docs, question=query)\n",
    "# print('Response:', response)\n",
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know.\n"
     ]
    }
   ],
   "source": [
    "query = \"Who is Chean?\"\n",
    "resp = answer_QA_chain(query)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The key components are:__\n",
    "- Document processing: Loading and splitting text.\n",
    "- Embeddings: Using HuggingFace embeddings to convert text into vectors.\n",
    "- Vector store (FAISS): Storing and retrieving document vectors efficiently.\n",
    "- Question Answering (RetrievalQA): Answering queries based on the stored documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@onkarmishra/using-langchain-for-question-answering-on-own-data-3af0a82789ed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
